#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Sep 26 00:59:25 2019

@author: rajdeepghosh
"""

#Naive Bayes


import pandas as pd
import numpy as np
import math
import re
import nltk
nltk.download('stopwords')
nltk.download('punkt')
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline


from nltk.tokenize import word_tokenize


stemmer = PorterStemmer()

d_train = open("deceptive.txt")
t_train=open("truthful.txt")
d_val = open("deceptiveval.txt")
t_val = open("truthfulval.txt")
test=open("test.txt")

test_data = pd.read_csv('test.txt', sep="\n", encoding='ISO-8859-1',header = None)
train_d = pd.read_csv('deceptive.txt', sep="\n", encoding='ISO-8859-1',header = None)
train_t = pd.read_csv('truthful.txt', sep="\n", encoding='ISO-8859-1',header = None)
t_val = pd.read_csv('truthfulval.txt', sep="\n", encoding='ISO-8859-1',header = None)
d_val= pd.read_csv('deceptiveval.txt', sep="\n", encoding='ISO-8859-1',header = None)
test_data.columns=["Review"]
train_d .columns=["Review"]
d_val .columns=["Review"]
t_val .columns=["Review"]
train_t.columns=["Review"]
#Combine datasets

train_d["Label"] = 1
train_t["Label"] = 0
d_val["Label"] = 1
t_val["Label"] = 0

train = [train_d,train_t]
train_data = pd.concat(train)
train_data.reset_index(inplace=True)
train_data.reset_index(inplace=True)
train_data.drop(["index"],inplace=True,axis=1)
train_data.rename(columns = {'level_0':'Index'}, inplace=True)

val = [d_val,t_val]
val_data = pd.concat(val)
val_data.reset_index(inplace=True)
val_data.reset_index(inplace=True)
val_data.drop(["index"],inplace=True,axis=1)
val_data.rename(columns = {'level_0':'Index'}, inplace=True)







# Data Preprocessing
def preprocess(test_data):
    final_corpus=[]
    for i in range(0,len(test_data)):
         #review = re.sub('[^a-zA-Z]', ' ', test_data['Review'][i])
         review=test_data['Review'][i]
         review=review.lower()
         tokenized_review = word_tokenize(review)
         #for word in tokenized_review:
             #if word in stopwords.words('english'):
                 #tokenized_review.remove(word)
         #for j in range(len(tokenized_review)):
             #tokenized_review[j] = stemmer.stem(tokenized_review[j])   
         final_review = " ".join(tokenized_review)
         final_corpus.append(final_review)
    return final_corpus
 
    

training_corpus = preprocess(train_data)
test_corpus = preprocess(test_data)
Val_corpus = preprocess(val_data)



    
from sklearn.feature_extraction.text import CountVectorizer
matrix = CountVectorizer(max_features=1500)
X = matrix.fit_transform(training_corpus).toarray()    
y = train_data.iloc[:, 2].values
test_data_X = matrix.transform(test_corpus).toarray()
val_data_X = matrix.transform(Val_corpus).toarray()
val_data_y=val_data.iloc[:, 2].values

# split train and test data
#from sklearn.model_selection import train_test_split
#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)



from sklearn.naive_bayes import  MultinomialNB
classifier = MultinomialNB()
classifier.fit(X, y)

# Predict Class
y_pred = classifier.predict(val_data_X)

# Accuracy 
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(val_data_y, y_pred)     
print(accuracy)


y_pred_test=classifier.predict(test_data_X)


     


output = pd.DataFrame({'Id': test_data.index,
                       'Prediction': y_pred_test})
output.to_csv('submission_test3.csv', index=False)
         